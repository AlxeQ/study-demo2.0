import streamlit as st
import pandas as pd
from collections import Counter
import jieba
import re

st.set_page_config(page_title="ä¸»è§‚é¢˜å…³é”®è¯åˆ†æå·¥å…·", layout="wide")

st.title("ğŸ“Š ä¸»è§‚é¢˜å…³é”®è¯åˆ†æå·¥å…·")

uploaded_file = st.file_uploader("è¯·ä¸Šä¼ åŒ…å«ä¸»è§‚é¢˜å†…å®¹çš„ Excel æ–‡ä»¶ï¼ˆ.xlsxï¼‰", type=["xlsx"])

def extract_keywords(texts, stopwords):
    all_words = []
    for text in texts:
        if pd.isna(text):
            continue
        text = re.sub(r'[^ä¸€-é¾¥]', '', str(text))  # åªä¿ç•™ä¸­æ–‡
        words = jieba.lcut(text)
        words = [w for w in words if w not in stopwords and len(w) > 1]
        all_words.extend(words)
    return Counter(all_words)

if uploaded_file:
    df = pd.read_excel(uploaded_file)
    st.write("ğŸ“„ æ•°æ®é¢„è§ˆï¼š", df.head())

    # é€‰æ‹©ä¸»è§‚é¢˜åˆ—
    text_column = st.selectbox("è¯·é€‰æ‹©ä¸»è§‚é¢˜æ–‡æœ¬æ‰€åœ¨çš„åˆ—", df.columns)

    # åŠ è½½å¸¸è§åœç”¨è¯ï¼ˆå¯è‡ªå®šä¹‰æ‰©å±•ï¼‰
    stopwords = set(["çš„", "äº†", "å’Œ", "æ˜¯", "æˆ‘", "ä¹Ÿ", "å°±", "åœ¨", "è¦", "ä¼š", "èƒ½", "ä¸", "ä¸€ä¸ª", "å¦‚ä½•", "é—®é¢˜", "æ¯”è¾ƒ", "ç›®å‰"])

    # æå–å…³é”®è¯
    keyword_counts = extract_keywords(df[text_column], stopwords)

    if keyword_counts:
        result_df = pd.DataFrame(keyword_counts.items(), columns=["å…³é”®è¯", "é¢‘æ¬¡"])
        result_df.index += 1
        result_df.reset_index(inplace=True)
        result_df.rename(columns={"index": "åºå·"}, inplace=True)

        st.success("âœ… åˆ†æå®Œæˆï¼Œç»“æœå¦‚ä¸‹ï¼š")
        st.dataframe(result_df)

        # ä¸‹è½½é“¾æ¥
        csv = result_df.to_csv(index=False, encoding="utf-8-sig")
        st.download_button("ğŸ“¥ ä¸‹è½½å…³é”®è¯åˆ†æç»“æœ", data=csv, file_name="å…³é”®è¯åˆ†æç»“æœ.csv", mime="text/csv")
    else:
        st.warning("âš ï¸ æ²¡æœ‰æå–åˆ°å…³é”®è¯ï¼Œè¯·æ£€æŸ¥ä¸Šä¼ æ–‡ä»¶æˆ–æ–‡æœ¬å†…å®¹ã€‚")
